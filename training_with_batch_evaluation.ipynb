{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10870508,"sourceType":"datasetVersion","datasetId":6753536}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Resnet34","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/classification_models.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Land Use Land Cover with U-Net\n## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nimport classification_models.tfkeras as tfkeras\nfrom classification_models.tfkeras import Classifiers\nfrom tensorflow.keras.metrics import MeanIoU, Precision, Recall\nimport random\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get an understanding by looking at a few random images and masks\ntrain_img_dir = \"/kaggle/input/lulc-data/data_for_training_and_testing/train/images/\"\ntrain_mask_dir = \"/kaggle/input/lulc-data/data_for_training_and_testing/train/masks/\"\n\nimg_list = os.listdir(train_img_dir)\nmsk_list = os.listdir(train_mask_dir)\n\nnum_images = len(os.listdir(train_img_dir))\n\nimg_num = random.randint(0, num_images-1)\n\nimg_for_plot = cv2.imread(train_img_dir + img_list[img_num], 1)\nimg_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n\nmask_for_plot = cv2.imread(train_mask_dir + msk_list[img_num], 0)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(121)\nplt.imshow(img_for_plot)\nplt.title('Image')\nplt.subplot(122)\nplt.imshow(mask_for_plot, cmap='gray')\nplt.title('Mask')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining Data Generators ensuring correct image loading and shuffling","metadata":{}},{"cell_type":"code","source":"# Define Generator for images and masks\nseed = 24\nbatch_size = 16\nn_classes = 4\n\nfrom keras.utils import to_categorical\n\n# Use this to preprocess input for transfer learning\nBACKBONE = 'resnet34'\nResNet34, preprocess_input = Classifiers.get(BACKBONE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a function to perform additional preprocessing\ndef preprocess_data(img, mask, num_class):\n    # Normalize images to [0, 1] manually (compatible with TensorFlow)\n    img = img.astype(np.float32) / 255.0\n    img = preprocess_input(img)  # Preprocess based on the pretrained backbone...\n    # Ensure mask values are within [0, num_class-1]\n    mask = np.clip(mask, 0, num_class - 1).astype(np.uint8)\n    mask = to_categorical(mask, num_class)\n    return (img, mask)\n\n# Define a custom generator for semantic segmentation\ndef custom_generator(img_dir, mask_dir, batch_size, num_class):\n    img_list = os.listdir(img_dir)\n    mask_list = os.listdir(mask_dir)\n    if len(img_list) != len(mask_list):\n        raise ValueError(\"Mismatch between image and mask counts\")\n    while True:\n        for start in range(0, len(img_list), batch_size):\n            img_batch = []\n            mask_batch = []\n            end = min(start + batch_size, len(img_list))\n            for img_path, mask_path in zip(img_list[start:end], mask_list[start:end]):\n                img = cv2.imread(os.path.join(img_dir, img_path))\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                mask = cv2.imread(os.path.join(mask_dir, mask_path), 0)\n                if img is None or mask is None:\n                    print(f\"Failed to load: {img_path} or {mask_path}\")\n                    continue\n                img, mask = preprocess_data(img, mask, num_class)\n                img_batch.append(img)\n                mask_batch.append(mask)\n            yield np.array(img_batch), np.array(mask_batch)\n\ntrain_img_gen = custom_generator(train_img_dir, train_mask_dir, batch_size, n_classes)\nval_img_dir = \"/kaggle/input/lulc-data/data_for_training_and_testing/val/images/\"\nval_mask_dir = \"/kaggle/input/lulc-data/data_for_training_and_testing/val/masks/\"\nval_img_gen = custom_generator(val_img_dir, val_mask_dir, batch_size, n_classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Verification","metadata":{}},{"cell_type":"code","source":"# Make sure the generator is working\nnum_samples = 2  \nfor _ in range(num_samples // batch_size + 1):\n    try:\n        x, y = next(train_img_gen)\n        for i in range(min(num_samples, x.shape[0])):\n            image = x[i]\n            mask = np.argmax(y[i], axis=2)\n            plt.figure(figsize=(12, 5))\n            plt.subplot(121)\n            plt.imshow(image)\n            plt.title(f' Sample Training Image {i+1}')\n            plt.subplot(122)\n            plt.imshow(mask, cmap='gray')\n            plt.title(f'Sample Training Mask {i+1}')\n            plt.show()\n    except StopIteration:\n        break\n\nfor _ in range(num_samples // batch_size + 1):\n    try:\n        x_val, y_val = next(val_img_gen)\n        for i in range(min(num_samples, x_val.shape[0])):\n            image = x_val[i]\n            mask = np.argmax(y_val[i], axis=2)\n            plt.figure(figsize=(12, 5))\n            plt.subplot(121)\n            plt.imshow(image)\n            plt.title(f' Sample Validation Image {i+1}')\n            plt.subplot(122)\n            plt.imshow(mask, cmap='gray')\n            plt.title(f'Sample Validation Mask {i+1}')\n            plt.show()\n    except StopIteration:\n        break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining and Training U-Net Model","metadata":{}},{"cell_type":"code","source":"# Define the model metrics and load model\nnum_train_imgs = len(os.listdir(train_img_dir))\nnum_val_images = len(os.listdir(val_img_dir))\nsteps_per_epoch = num_train_imgs // batch_size\nval_steps_per_epoch = num_val_images // batch_size\n\nIMG_HEIGHT = x.shape[1]\nIMG_WIDTH = x.shape[2]\nIMG_CHANNELS = x.shape[3]\n\nn_classes = 4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the U-Net model with ResNet34 as backbone (encoder) and custom decoder\ndef unet_resnet34(input_shape, n_classes):\n    # Load ResNet34 backbone as encoder\n    backbone = ResNet34(input_shape=input_shape, weights='imagenet', include_top=False)\n    \n    # Extract layers from ResNet34 for the encoder\n    conv1 = backbone.get_layer(\"relu0\").output  # Initial block after input\n    conv2 = backbone.get_layer(\"stage2_unit1_relu1\").output  # After stage 2\n    conv3 = backbone.get_layer(\"stage3_unit1_relu1\").output  # After stage 3\n    conv4 = backbone.get_layer(\"stage4_unit1_relu1\").output  # After stage 4\n    conv5 = backbone.get_layer(\"relu1\").output  # Final block before top\n\n    # Decoder (U-Net style)\n    up6 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv5)\n    up6 = tf.keras.layers.Concatenate()([up6, conv4])\n    conv6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv6)\n    up7 = tf.keras.layers.Concatenate()([up7, conv3])\n    conv7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv7)\n    up8 = tf.keras.layers.Concatenate()([up8, conv2])\n    conv8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv8)\n    up9 = tf.keras.layers.Concatenate()([up9, conv1])\n    conv9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n\n    up10 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv9)\n    conv10 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up10)\n    conv10 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv10)\n\n    outputs = tf.keras.layers.Conv2D(n_classes, (1, 1), activation='softmax')(conv10)\n    model = tf.keras.Model(inputs=[backbone.input], outputs=[outputs])\n    return model\n\n# Create and compile the model\nmodel = unet_resnet34(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), n_classes=n_classes)\nmodel.compile('Adam', loss='categorical_crossentropy', metrics=[MeanIoU(num_classes=n_classes)])\n\nprint(model.summary())\nprint(model.input_shape)# Define the model metrics and load model\nnum_train_imgs = len(os.listdir(train_img_dir))\nnum_val_images = len(os.listdir(val_img_dir))\nsteps_per_epoch = num_train_imgs // batch_size\nval_steps_per_epoch = num_val_images // batch_size\n\nIMG_HEIGHT = x.shape[1]\nIMG_WIDTH = x.shape[2]\nIMG_CHANNELS = x.shape[3]\n\nn_classes = 4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_img_gen,\n          steps_per_epoch=steps_per_epoch,\n          epochs=100,\n          verbose=1,\n          validation_data=val_img_gen,\n          validation_steps=val_steps_per_epoch)\n\nmodel.save('landcover_RESNET_backbone_batch16.hdf5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('landcover_RESNET_backbone_batch16.hdf5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the training and validation IoU and loss\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nacc = history.history['mean_io_u']\nval_acc = history.history['val_mean_io_u']\n\nplt.plot(epochs, acc, 'y', label='Training IoU')\nplt.plot(epochs, val_acc, 'r', label='Validation IoU')\nplt.title('Training and validation IoU')\nplt.xlabel('Epochs')\nplt.ylabel('IoU')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Predictions and Visualisation\n## 1.Predictions made on Original Dataset","metadata":{}},{"cell_type":"code","source":"# Load and evaluate the model\nfrom keras.models import load_model\n\nmodel = load_model(\"landcover_RESNET_backbone_batch16.hdf5\", compile=False)\n\n# Test generator using validation data\ntest_image_batch, test_mask_batch = val_img_gen.__next__()\n\n# Convert categorical to integer for visualization and IoU calculation\ntest_mask_argmaxed = np.argmax(test_mask_batch, axis=3)\ntest_pred_batch = model.predict(test_image_batch)\ntest_pred_argmaxed = np.argmax(test_pred_batch, axis=3)\n\nn_classes = 4\nIOU_keras = MeanIoU(num_classes=n_classes)\nIOU_keras.update_state(test_pred_argmaxed, test_mask_argmaxed)\nprint(\"Mean IoU (Validation) =\", IOU_keras.result().numpy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# View a few images, masks, and corresponding predictions from validation\nfor i in range(5):  \n    # Fetch a new batch for each visualization to ensure randomness\n    test_image_batch, test_mask_batch = val_img_gen.__next__()\n    test_pred_batch = model.predict(test_image_batch)\n    test_mask_argmaxed = np.argmax(test_mask_batch, axis=3)\n    test_pred_argmaxed = np.argmax(test_pred_batch, axis=3)\n    \n    img_num = random.randint(0, test_image_batch.shape[0]-1)\n    plt.figure(figsize=(12, 8))\n    plt.subplot(231)\n    plt.title(f'Sample Image {i+1}')\n    plt.imshow(test_image_batch[img_num])\n    plt.subplot(232)\n    plt.title(f'Sample Mask {i+1}')\n    plt.imshow(test_mask_argmaxed[img_num])\n    plt.subplot(233)\n    plt.title(f' Predicted Image {i+1}')\n    plt.imshow(test_pred_argmaxed[img_num])\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.Predictions made on Test Dataset","metadata":{}},{"cell_type":"code","source":"# Test generator using new testing dataset\ntest_img_dir = \"/kaggle/input/lulc-data/data_for_training_and_testing/test/images/\"\ntest_mask_dir = \"/kaggle/input/lulc-data/data_for_training_and_testing/test/masks/\"\nnew_test_img_gen = custom_generator(test_img_dir, test_mask_dir, batch_size, n_classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate on new test dataset\nnew_test_image_batch, new_test_mask_batch = new_test_img_gen.__next__()\n\n# Convert categorical to integer for visualization and IoU calculation for new test\nnew_test_mask_argmaxed = np.argmax(new_test_mask_batch, axis=3)\nnew_test_pred_batch = model.predict(new_test_image_batch)\nnew_test_pred_argmaxed = np.argmax(new_test_pred_batch, axis=3)\n\nn_classes = 4\nIOU_keras = MeanIoU(num_classes=n_classes)\nIOU_keras.update_state(new_test_pred_argmaxed, new_test_mask_argmaxed)\nprint(\"Mean IoU (New Test) =\", IOU_keras.result().numpy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize 5 random samples from new test dataset\nfor i in range(5):  \n    new_test_image_batch, new_test_mask_batch = new_test_img_gen.__next__()\n    new_test_pred_batch = model.predict(new_test_image_batch)\n    new_test_mask_argmaxed = np.argmax(new_test_mask_batch, axis=3)\n    new_test_pred_argmaxed = np.argmax(new_test_pred_batch, axis=3)\n    \n    img_num = random.randint(0, new_test_image_batch.shape[0]-1)\n    plt.figure(figsize=(12, 8))\n    plt.subplot(231)\n    plt.title(f'New Testing Image {i+1}')\n    plt.imshow(new_test_image_batch[img_num])\n    plt.subplot(232)\n    plt.title(f'New Testing Mask {i+1}')\n    plt.imshow(new_test_mask_argmaxed[img_num])\n    plt.subplot(233)\n    plt.title(f' New Predicted Image {i+1}')\n    plt.imshow(new_test_pred_argmaxed[img_num])\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Comparing the performance between Original Dataset and New Dataset","metadata":{}},{"cell_type":"code","source":"def calculate_metrics(y_true, y_pred):\n    precision = Precision()(y_true, y_pred).numpy()\n    recall = Recall()(y_true, y_pred).numpy()\n    iou = MeanIoU(num_classes=n_classes)(y_true, y_pred).numpy()\n    return {'IoU': iou, 'Precision': precision, 'Recall': recall}\n\nval_metrics = calculate_metrics(test_mask_argmaxed, test_pred_argmaxed)\ntest_metrics = calculate_metrics(new_test_mask_argmaxed, new_test_pred_argmaxed)\n\nmetrics_df = pd.DataFrame({\n    'Dataset': ['Validation', 'Test'],\n    'IoU': [val_metrics['IoU'], test_metrics['IoU']],\n    'Precision': [val_metrics['Precision'], test_metrics['Precision']],\n    'Recall': [val_metrics['Recall'], test_metrics['Recall']]\n})\nprint(\"\\n==================== PERFORMANCE METRICS COMPARISON ====================\")\nprint(\"Metric    |   Validation |        Test |       Diff\")\nprint(\"---------------------------------------------------------\")\nprint(f\"IoU       |    {metrics_df.loc[0, 'IoU']:.4f} |    {metrics_df.loc[1, 'IoU']:.4f} |     {(metrics_df.loc[1, 'IoU'] - metrics_df.loc[0, 'IoU']):.4f}\")\nprint(f\"Precision |    {metrics_df.loc[0, 'Precision']:.4f} |    {metrics_df.loc[1, 'Precision']:.4f} |     {(metrics_df.loc[1, 'Precision'] - metrics_df.loc[0, 'Precision']):.4f}\")\nprint(f\"Recall    |    {metrics_df.loc[0, 'Recall']:.4f} |    {metrics_df.loc[1, 'Recall']:.4f} |     {(metrics_df.loc[1, 'Recall'] - metrics_df.loc[0, 'Recall']):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize performance comparison (Original vs. New Test Dataset)\nval_iou = IOU_keras.result().numpy()\nval_loss = np.mean(tf.keras.losses.categorical_crossentropy(test_mask_batch, test_pred_batch))\nnew_test_iou = IOU_keras.result().numpy()\nnew_test_loss = np.mean(tf.keras.losses.categorical_crossentropy(new_test_mask_batch, new_test_pred_batch))\n\nmetrics = ['Loss', 'Mean IoU']\noriginal_values = [val_loss, val_iou]\nnew_values = [new_test_loss, new_test_iou]\n\nplt.figure(figsize=(10, 6))\nx = np.arange(len(metrics))\nwidth = 0.35\n\nplt.bar(x - width/2, original_values, width, label='Original (Validation)', color='#B22222')\nplt.bar(x + width/2, new_values, width, label='New Test', color='#D3D3D3')\nplt.xlabel('Metrics')\nplt.ylabel('Value')\nplt.title('Performance Comparison: Original vs. New Test Dataset')\nplt.xticks(x, metrics)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Post Training Visualisations","metadata":{}},{"cell_type":"markdown","source":"#### 3. Confusion Matrix Analysis:\n    Presents heatmaps showing prediction errors for validation and test datasets, revealing which classes the model confuses.\n\n#### 4. Prediction Visualization:\n    Visualizes random images, true masks, predicted masks, and errors from validation and test datasets to inspect model predictions visually.\n\n#### 5. Class Distribution Analysis:\n    Plots bar charts of class counts (Background, Buildings, Woodlands, Water) in validation and test datasets to identify data imbalances.\n\n#### 6. Probability Calibration Analysis:\n    Draws density curves of predicted probabilities for each class in validation and test datasets to assess model confidence.\n\n#### 7. Detailed Performance Comparison:\n    Creates a bar chart comparing IoU, Precision, and Recall between validation and test datasets to evaluate generalization.\n\n#### 8. Per-Class IoU Analysis:\n    Displays bar charts of IoU for each class (0–3) in validation and test datasets to highlight individual class performance.","metadata":{}},{"cell_type":"code","source":"# 3. Confusion Matrix Analysis\n\ndef plot_confusion_matrix(y_true, y_pred, title):\n    cm = confusion_matrix(y_true.flatten(), y_pred.flatten())\n    plt.figure(figsize=(8,6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=[f'Class {i}' for i in range(n_classes)],\n                yticklabels=[f'Class {i}' for i in range(n_classes)])\n    plt.title(f'Confusion Matrix ({title})')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\nplot_confusion_matrix(test_mask_argmaxed, test_pred_argmaxed, 'Validation Set')\nplot_confusion_matrix(new_test_mask_argmaxed, new_test_pred_argmaxed, 'Test Set')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Prediction Visualization\n\ndef plot_predictions(images, masks, preds, num_samples=3):\n    indices = np.random.choice(len(images), num_samples)\n    plt.figure(figsize=(15, num_samples*4))\n    \n    for i, idx in enumerate(indices):\n        plt.subplot(num_samples, 4, i*4+1)\n        plt.imshow(images[idx])\n        plt.title(f'Image {idx}')\n        plt.axis('off')\n        \n        plt.subplot(num_samples, 4, i*4+2)\n        plt.imshow(masks[idx])\n        plt.title('True Mask')\n        plt.axis('off')\n        \n        plt.subplot(num_samples, 4, i*4+3)\n        plt.imshow(preds[idx])\n        plt.title('Predicted Mask')\n        plt.axis('off')\n        \n        plt.subplot(num_samples, 4, i*4+4)\n        error = np.where(masks[idx] != preds[idx], 1, 0)\n        plt.imshow(error)\n        plt.title(f'Errors: {error.sum()}')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nprint(\"\\nValidation Set Predictions:\")\nplot_predictions(test_image_batch, test_mask_argmaxed, test_pred_argmaxed)\n\nprint(\"\\nTest Set Predictions:\")\nplot_predictions(new_test_image_batch, new_test_mask_argmaxed, new_test_pred_argmaxed)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Class Distribution Analysis\n\ndef plot_class_distribution(*masks_list, titles):\n    plt.figure(figsize=(15, 5))\n    colors = sns.color_palette('husl', len(masks_list))\n    \n    for i, masks in enumerate(masks_list):\n        counts = np.bincount(masks.flatten(), minlength=n_classes)\n        plt.subplot(1, len(masks_list), i+1)\n        plt.bar(range(n_classes), counts, color=colors[i])\n        plt.title(titles[i])\n        plt.xlabel('Class')\n        plt.ylabel('Count')\n        plt.xticks(range(n_classes))\n    plt.tight_layout()\n    plt.show()\n\nplot_class_distribution(\n    test_mask_argmaxed, new_test_mask_argmaxed,\n    titles=['Validation Class Distribution', 'Test Class Distribution']\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Probability Calibration Analysis\n\ndef plot_probability_distribution(predictions, title):\n    plt.figure(figsize=(12, 6))\n    for class_idx in range(n_classes):\n        sns.kdeplot(predictions[..., class_idx].flatten(), \n                    label=f'Class {class_idx}', linewidth=2)\n    plt.title(f'Class Probability Distribution ({title})')\n    plt.xlabel('Predicted Probability')\n    plt.ylabel('Density')\n    plt.legend()\n    plt.show()\n\nprint(\"\\nValidation Probability Distributions:\")\nplot_probability_distribution(test_pred_batch, 'Validation')\n\nprint(\"\\nTest Probability Distributions:\")\nplot_probability_distribution(new_test_pred_batch, 'Test')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Detailed Performance Comparison\n\ndef plot_metric_comparison(val_metrics, test_metrics):\n    metrics = ['IoU', 'Precision', 'Recall']\n    val_values = [val_metrics[m] for m in metrics]\n    test_values = [test_metrics[m] for m in metrics]\n    \n    x = np.arange(len(metrics))\n    width = 0.35\n    \n    plt.figure(figsize=(10, 6))\n    plt.bar(x - width/2, val_values, width, label='Validation', color='navy')\n    plt.bar(x + width/2, test_values, width, label='Test', color='#87CEEB')\n    \n    plt.title('Performance Metric Comparison')\n    plt.ylabel('Score')\n    plt.xticks(x, metrics)\n    plt.ylim(0, 1)\n    plt.legend()\n    plt.show()\n\nplot_metric_comparison(val_metrics, test_metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 8. Per-Class IoU Analysis\n\ndef plot_class_iou(y_true, y_pred, title):\n    class_iou = []\n    for class_id in range(n_classes):\n        iou = MeanIoU(num_classes=n_classes)\n        iou.update_state(y_true == class_id, y_pred == class_id)\n        class_iou.append(iou.result().numpy())\n    \n    plt.figure(figsize=(10, 6))\n    colors = sns.color_palette('viridis', n_classes)\n    plt.bar(range(n_classes), class_iou, color=colors)\n    plt.title(f'Per-Class IoU ({title})')\n    plt.xlabel('Class')\n    plt.ylabel('IoU')\n    plt.xticks(range(n_classes))\n    plt.ylim(0, 1)\n    \n\nprint(\"\\nValidation Set Class IoU:\")\nplot_class_iou(test_mask_argmaxed, test_pred_argmaxed, 'Validation')\n\nprint(\"\\nTest Set Class IoU:\")\nplot_class_iou(new_test_mask_argmaxed, new_test_pred_argmaxed, 'Test')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}